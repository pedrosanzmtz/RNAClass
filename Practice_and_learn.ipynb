{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice and learn TensorFlow\n",
    "\n",
    "As we saw in the introduction where we trained a linear regression model using tensorflow, we can algo train a logistic regression following the same steps, just change a litle bit the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "Of course there is not such a tutorial in the official web page, well almost like these tutorials i really recommend and i learnt a lot:\n",
    "\n",
    "[GitHub aymericdamien](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/logistic_regression.ipynb)\n",
    "\n",
    "[Gentlest Intro to Tensorflow #4: Logistic Regression](https://medium.com/all-of-us-are-belong-to-machines/gentlest-intro-to-tensorflow-4-logistic-regression-2afd0cabc54)\n",
    "\n",
    "[Lecture note 3: Linear and Logistic Regression in TensorFlow](http://web.stanford.edu/class/cs20si/lectures/notes_03.pdf)\n",
    "\n",
    "[Using Logistic and Softmax Regression in TensorFlow](https://blog.altoros.com/using-logistic-and-softmax-regression-in-tensorflow.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "We will use tensorflow to create the graph and train the model and use numpy to handle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First we load the iris data set that was downloaded from the web page: \n",
    "\n",
    "[training](http://download.tensorflow.org/data/iris_training.csv)\n",
    "\n",
    "[test](http://download.tensorflow.org/data/iris_test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('iris_training.csv', skiprows=1, delimiter=',')\n",
    "test = np.loadtxt('iris_test.csv', skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "\n",
    "We need to split the data to X and y, remember, the iris dataset has the first four columns and features and the fifth column is the y value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:, :4]\n",
    "y_train = train[:, 4]\n",
    "\n",
    "X_test = test[:, :4]\n",
    "y_test = test[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical\n",
    "\n",
    "As we are doing classification, we the to pass the values to one hot encoding\n",
    "Example: \n",
    "\n",
    "[[0], \n",
    "\n",
    " [1],\n",
    " \n",
    " [2]]\n",
    " \n",
    "to:\n",
    "\n",
    "[[1, 0, 0],\n",
    "\n",
    " [0, 1, 0],\n",
    " \n",
    " [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.eye(3)[y_train.astype('int')]\n",
    "y_test = np.eye(3)[y_test.astype('int')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Features and classes\n",
    "\n",
    "To train this model we need to declare how many features we have and how many classes\n",
    "\n",
    "Features:\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "\n",
    "Classes: \n",
    "1. Iris Setosa \n",
    "2. Iris Versicolour \n",
    "3. Iris Virginica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_class = y_train.shape[1]\n",
    "n_feature = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of iterations and learning rate declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "max_iter = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "\n",
    "Remember a placeholder is a variable that we dont specify the value until the model is trained or evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_feature])\n",
    "y = tf.placeholder(tf.float32, [None, n_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Remember linear regression?\n",
    "\n",
    "y = W * x + b\n",
    "\n",
    "Now me have multiples values for x, so we need multiple values for w and b, here we initialize theses values with zeros because for tensorflow is easier to initiliaze values in zeros than other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([n_feature, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "The difference here is that we are doing classification, here softmax help us to have values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yp = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loss function also change\n",
    "\n",
    "Entropy = y * log(yp)\n",
    "\n",
    "The probabilty of a event  multiply by the logarithm of this event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(yp), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer are always used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a variable train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create session and initiliaze all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "If we train the model once, we will have a big loss, it is necessary to iterate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_iter):\n",
    "    sess.run(train, {x: X_train, y: y_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reassigning W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.15325952,  1.05496025, -1.17063189],\n",
       "        [ 3.78091812, -0.79020143, -4.81830502],\n",
       "        [-4.27292204, -0.09086238,  4.60043001],\n",
       "        [-4.38079691, -4.96103859,  4.62627363]], dtype=float32),\n",
       " array([ 4.42134619,  7.47800398, -6.16095543], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_value, b_value = sess.run([W, b])\n",
    "\n",
    "fixW = tf.assign(W, W_value)\n",
    "fixb = tf.assign(b, b_value)\n",
    "\n",
    "sess.run([fixW, fixb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061108276"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value = sess.run(loss, {x: X_test, y: y_test})\n",
    "\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's time to predict and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.21003159e-03,   9.87415254e-01,   8.37475527e-03],\n",
       "       [  1.27234216e-06,   1.82769559e-02,   9.81721759e-01],\n",
       "       [  9.96698260e-01,   3.30179161e-03,   2.74432068e-14],\n",
       "       [  7.92105962e-03,   9.77954388e-01,   1.41245406e-02],\n",
       "       [  8.48661235e-04,   9.90333736e-01,   8.81752279e-03],\n",
       "       [  1.62434275e-03,   9.96851385e-01,   1.52429764e-03],\n",
       "       [  9.99982357e-01,   1.76659432e-05,   2.21522022e-20],\n",
       "       [  2.69221273e-05,   6.52997613e-01,   3.46975416e-01],\n",
       "       [  5.56060392e-03,   9.92929757e-01,   1.50965026e-03],\n",
       "       [  1.99898209e-09,   2.88318028e-03,   9.97116804e-01],\n",
       "       [  1.03127791e-08,   1.85686711e-03,   9.98143077e-01],\n",
       "       [  9.98553455e-01,   1.44651928e-03,   3.09133356e-16],\n",
       "       [  9.87585850e-07,   8.31789803e-03,   9.91681159e-01],\n",
       "       [  3.36662866e-04,   9.80132282e-01,   1.95310917e-02],\n",
       "       [  1.91784333e-04,   9.99256551e-01,   5.51647914e-04],\n",
       "       [  9.99549448e-01,   4.50476538e-04,   2.30751809e-17],\n",
       "       [  9.29970481e-03,   9.90679920e-01,   2.03906966e-05],\n",
       "       [  9.94101346e-01,   5.89862978e-03,   9.20092080e-15],\n",
       "       [  9.98919725e-01,   1.08030136e-03,   1.32341354e-16],\n",
       "       [  3.91323880e-08,   1.95386214e-03,   9.98046041e-01],\n",
       "       [  9.97582316e-01,   2.41771340e-03,   3.88209149e-16],\n",
       "       [  1.10467302e-03,   9.35684383e-01,   6.32108822e-02],\n",
       "       [  1.43344991e-07,   1.49687855e-02,   9.85031009e-01],\n",
       "       [  1.42365734e-05,   5.89551926e-01,   4.10433769e-01],\n",
       "       [  3.14519135e-03,   9.96367216e-01,   4.87559650e-04],\n",
       "       [  7.59322662e-04,   9.85827029e-01,   1.34137301e-02],\n",
       "       [  9.99953747e-01,   4.62675343e-05,   1.03712719e-19],\n",
       "       [  8.90508411e-04,   9.89240170e-01,   9.86934267e-03],\n",
       "       [  8.64648886e-09,   1.41159559e-04,   9.99858856e-01],\n",
       "       [  1.65744743e-03,   9.97365415e-01,   9.77195334e-04]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = sess.run(yp, {x: X_test})\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2,\n",
       "       1, 1, 1, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = np.argmax(predicted, axis=1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2,\n",
       "       1, 1, 1, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The value we got wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
